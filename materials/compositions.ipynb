{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар по композициям алгоритмов \n",
    "\n",
    "### Предсказания в композициях\n",
    "\n",
    "__Вспомнить из лекции:__\n",
    "* Что такое композиция алгоритмов? Что такое базовый алгоритм? Для чего вводят веса при алгоритмах?\n",
    "* Что такое голосование алгоритмов? Что такое усреднение выходов алгоритмов?\n",
    "* Приведите несколько примеров композиций алгоритмов.\n",
    "\n",
    "Композиции алгоритмов позволяют составлять более сложный и более эффективный алгоритм из нескольких более простых (базовых) алгоритмов. В зависимости от того, что используется в качестве базового алгоритма, композиции можно разделить на две группы:\n",
    "* композиции большого числа слабых алгоритмов;\n",
    "* композиции малого числа сильных алгоритмов.\n",
    "В первой группе каждый базовый алгоритм показывает плохое качество, зато в композиции получается хорошее качество. Обучить и настроить такие слабые базовые алгоритмы не очень сложно, поэтому мы можем строить из них большие композиции.\n",
    "\n",
    "Во второй группе каждый базовый алгоритм - это уже хорошо работающий алгоритм. Однако композиция может работать еще лучше. Настройка каждого такого алгоритма занимает много времени (подбор гиперпараметров, выбор признаков и т. д.), поэтому в композиции второй группы обычно входит мало базовых алгоритмов.\n",
    "\n",
    "Часто композиции первой группы используют как базовый алгоритм второй группы.\n",
    "\n",
    "#### Вопрос: какие алгоритмы композиции относятся к каждой из групп?\n",
    "\n",
    "__Ответ:__\n",
    "\n",
    "К первой группе относятся бэггинг, случайный лес, градиентный бустинг. В них в качестве базового алгоритма используется фиксированное семейство алгоритмов (например, решающие деревья, хотя бэггинг и градиентный бустинг потенциально могут работать с любым безовым семейством алгоритмов). Суть алгоритма композиции в данном случае - задать процедуру, по которой из одной выборки можно получить много базовых алгоритмов одного семейства. Каждый алгоритм будет не очень сильным, но зато процедуру можно повторять много раз и получить много базовых алгоритмов. \n",
    "\n",
    "Во второй группе относятся блендинг и стекинг, а также другие простые алгоритмы композиции, например голосование или усреднение. В качестве базовых алгоритмов здесь обычно используют алгоритмы разных семейств (например, линейная модель и kNN) или алгоритмы одного семейства с разными значениями гиперпараметров.\n",
    "\n",
    "#### Задача 1.\n",
    "Чаще всего для объединения алгоритмов в композицию используют сумму предсказаний базовых алгоритмов с весами:\n",
    "\n",
    "$$a(x) = \\sum_{n=1}^N \\gamma_n b_n(x).$$\n",
    "\n",
    "Ответьте на вопросы:\n",
    "* Предполагается, что $b_n(x)$ - вещественное число. В регрессии предсказания удовлетворяют этому условию. Что можно брать в качестве $b(x)$ в классификации?\n",
    "* Какие веса $\\gamma_n$ нужно взять, если мы хотим усреднять предсказания базовых алгоритмов?\n",
    "* Какой вес $\\gamma_2$ при втором алгоритме нужно взять, если вес при первом алгоритме равне 0.25: $\\gamma_1=0.25$, и мы хотим, чтобы второй алгоритм вносил вклад в композицию в три раза больше?\n",
    "\n",
    "__Решение:__\n",
    "* В качестве $b(x)$ для регрессии берут вещественное предсказание, для классификации - например, вероятности классов. В последнем случае $b(x)$ - вектор длины число классов, и вся взвешенная сумма выполняется векторно.\n",
    "* При $\\gamma_n = \\frac 1 N \\, \\forall n$ все алгоритмы вносят одинаковый вклад в предсказание, и их предсказания усредняются.\n",
    "* При $\\gamma_2=0.75$ второй алгоритм вносит вклад в три раза больше, чем первый алгоритм.\n",
    "\n",
    "### Обучение композиций\n",
    "\n",
    "#### Бэггинг и случайный лес\n",
    "__Вспомнить из лекции:__\n",
    "* Что такое бэггинг? Как в бэггинге получают разные алгоритмы одного базового семейства на фиксированном наборе данных? Для каких семейств базовых алгоритмов можно использовать бэггинг?\n",
    "\n",
    "#### Задача 2.\n",
    "В бэггинге один базовый алгоритм обучается на выборке, сгенерированной из исходной методом случайного вытаскивания объектов с возвращением. \n",
    "Какова вероятность того, что конкретный объект попадет в выборку (встретится в ней не менее одного раза)? Длина исходной и сгенерированной выборок $\\ell$.\n",
    "\n",
    "__Решение.__\n",
    "В этой задаче проще найти вероятность $P$ того, что объект не попадет в выборку, и затем вычесть ее из единицы.\n",
    "Вероятность того, что мы вытащим не наш объект на одном шаге генерации выборки, равна $\\frac {\\ell-1} {\\ell}$ (подходят все объекты, кроме одного).\n",
    "Все шаги вытаскивания объектов независимы, поэтому $P$ равно произведению вероятности вытаскивания не нашего объекта на каждом шаге: $P = \\frac {\\ell-1} {\\ell} \\cdot \\dots \\cdot \\frac {\\ell-1} {\\ell} = \\bigl ( \\frac {\\ell-1} {\\ell} \\bigr)^\\ell$.  \n",
    "Итоговый ответ: $1-P = 1-\\bigl ( \\frac {\\ell-1} {\\ell} \\bigr)^\\ell$.\n",
    "\n",
    "Устремим $\\ell$ в бесконечность, тогда $1-\\bigl ( \\frac {\\ell-1} {\\ell} \\bigr)^\\ell \\rightarrow 1-\\frac 1 e \\approx 1-\\frac 1 {2.72} \\approx 0.63 $.\n",
    "\n",
    "В итоге, для больших выборок вероятность попадания объекта в выборку приблизительно равна 0.63. Другими словами, число различных объектов в выборке примерно равно $0.63\\ell$, или примерно две трети. Примерно треть объектов в выборке повторяется.\n",
    "\n",
    "Получается, что каждый базовый алгоритм в бэггинге настраивается на разном подмножестве объектов, причем у объектов могут быть разные веса (если объект несколько раз повторяется в выборке, это эквивлентно установлению веса перед объектом). Если взять базовые алгоритмы, которые получаются сильно различными на разных подмножествах объектов, то в итоговой композиции они компенсируют ошибки друг друга, повысив качество композиции. Этому свойству удовлетворяют, например, решающие деревья. В примере в практической части будет показана раздедяющая поверхность трех решающих деревьев, обученных бэггингом на синтетических данных с двумя признаками. Все три дерева сильно различны, хотя обучаются на подножествах одного множества объектов.\n",
    "\n",
    "#### Задача 3.\n",
    "В чем отличие обучения случайного леса от:\n",
    "* бэггинга над решающими деревьями?\n",
    "* бэггинга над решающими деревьями, в котором каждое решающее дерево обучается на случайно выбранном подмножестве признаков?\n",
    "* бэггинга над решающими деревьями, в котором при построении каждой вершины решающего дерева выбирается случайный признак?\n",
    "\n",
    "__Решение.__\n",
    "В случайном лесе пытаются добиться еще большей различности базовых решающих деревьев, добавляя к случайности по объектам (бэггинг) случайность по признакам. На практике хорошо работает следующий метод: каждый раз при построении одной вершины решающего дерева, мы будем перебирать не все признаки для поиска лучшего предиката, а только случайное подмножество признаков.\n",
    "\n",
    "Ответы:\n",
    "* В бэггинге есть только случайность по объектам, а в случайном лесе - еще и по признакам.\n",
    "* Если каждое решающее дерево обучается на случайно выбранном подмножестве признаков, то во всех вершинах этого дерева мы бы перебирали одно и то же подмножество признаков. А в случайном лесе подмножество признаков выбирается случано для каждой вершины.\n",
    "* Если при построении каждой вершины решающего дерева выбирается случайный признак, то это частный случай решающего дерева с размером подмножества, равным один. \n",
    "\n",
    "#### Вопрос: Каковы параметры и гиперпараметры случайного леса?\n",
    "\n",
    "__Ответ:__\n",
    "\n",
    "Параметры и гиперпараметры - те же самые, что у базовых алгоритмов, то есть решающих деревьев. К параметрам относятся признаки и пороги во внутренних вершинах всех деревьев, входящих в лес, а также все предсказания в листовых вершинах. К гиперпараметрам относят критерии останова: максимальная глубина, максимальное число листьев и т. д. Кроме того, добавляются гиперпараметры случайного леса: какой размер случайного подмножества признаков использовать в каждой вершине, а также число деревьев. Число деревьев для случайного леса обычно берут максимально возможным: чем больше деревьев, тем лучше качество случайного леса.\n",
    "\n",
    "#### Бустинг\n",
    "\n",
    "__Вспомнить из лекции:__\n",
    "* На какие целевые переменные настраивается один базовый алгоритм градиентного бустинга при использовании квадратичной функции потерь?\n",
    "* Как в градентном бустинге выбираются веса базовых алгоритмов?\n",
    "\n",
    "#### Задача 4.\n",
    "Дана выборка с пятью объектами и двумя признаками, задача регрессии:\n",
    "\n",
    "| Признак 1 | Признак 2 | Ответ |\n",
    "|-----------|-----------|-------|\n",
    "| 1         | -1        | 0.3   |\n",
    "| 2         | 1         | -0.4  |\n",
    "| 3         | 0         | 0.1   |\n",
    "| 1         | 0         | 0.2   |\n",
    "| 2         | -1        | -0.8  |\n",
    "\n",
    "Мы обучаем градиентный бустинг с квадратичной функцией потерь $L(y, z) = (y-z)^2$. Первый базовый алгоритм выбираем очень простым и константным: $b_0(x) = 0$. На какие целевые переменные будет настраиваться второй базовый алгоритм $b_1(x)$?\n",
    "\n",
    "__Решение.__\n",
    "В градиентном бустинге каждый следующий алгоритм \"дополняет\" ответы уже построенной, текущей композиции. В нашем примере уже построенная композиция состоит только из одного алгоритма, которым инициализируется градиентный бустинг: $a(x) = b_0(x)$. Чтобы реализовать логику \"дополнения\", мы будем менять целевые переменные, на которые настраивается базовый алгоритм. В этом принципиальное отличие градиентного бустинга от предыдущих рассмотренных алгоритмов композиции (бэггинга и случайного леса): в тех алгоритмах мы модифицируем состав объектов в выборке и рассматриваемые признаки, а в градиентном бустинге - целевые переменные, в то время как матрица объекты-признаки не меняется.\n",
    "\n",
    "В градиентном бустинге базовый алгоритм настраивается на вектор производных функции потерь: $- \\frac {\\partial L}{\\partial z}$, посчитанных для текущей композиции. Дл квадатичной функции потерь:\n",
    "\n",
    "$$- \\frac {\\partial L}{\\partial z} = - \\frac {\\partial (y-z)^2}{\\partial z} = -2(z-y) = 2(y-z).$$\n",
    "\n",
    "Вместо $z$ нужно подставить текущую композицию, то есть $z=b_0(x)$. У нас $b_0(x)=0$, поэтому алгоритм $b_1(x)$ будет настраиваться на вектор, состоящий из $2y$ для каждого объекта. Составляем вектор из столбца \"Ответ\": $(0.6, -0.8, 0.1, 0.2, -1.6)$ - это ответ.\n",
    "\n",
    "Алгоритму $b_1(x)$ все равно, на какой целевой вектор обучаться - на исходный или на полученный в задаче. В градиентном бустинге используют этот факт, чтобы следующие базовые алгоритмы могли \"дополнять\" предсказания предыдущих. В нашей задаче нужно также подобрать вес $\\gamma_1$ алгоритма $b_1(x)$. Предположим, что у нас получился вес $\\gamma_1=0.5$. Тогда предсказания композиции будут выполняться по формуле $b_0(x) + 0.5 b_1(x)$.\n",
    "\n",
    "__Обратите внимание:__ при составлении целевого вектора для $b_1(x)$ мы не использовали матрицу объекты-признаки, она дана в этой задаче только для того, чтобы показать полный контекст обучения алгоритма. Матрица будет использоваться, только когда мы будем обучать алгоритм $b_1(x)$ на полученный вектор.\n",
    "\n",
    "#### Вопрос: Каковы параметры и гиперпараметры градиентного бустинга над решающими деревьями?\n",
    "\n",
    "__Ответ:__\n",
    "\n",
    "Параметры и гиперпараметры - те же самые, что у базовых алгоритмов, то есть решающих деревьев. К параметрам относятся признаки и пороги во внутренних вершинах всех деревьев, входящих в лес, а также все предсказания в листовых вершинах. К гиперпараметрам относят критерии останова: максимальная глубина, максимальное число листьев и т. д. Кроме того, добавляются гиперпараметры градиентного бустинга: длина шага, а также число деревьев. Число деревьев для градиентного бустинга обычно подбирают, как и другие гиперпараметры: при очень большом числе деревьев градиентный бустинг начинает переобучаться.\n",
    "\n",
    "####  Стекинг и блендинг\n",
    "\n",
    "Блендинг - это автоматический подбор весов базовых алгоритмов с помощью линейной регрессии. Блендинг реализуется следующим образом: предсказания базовых алгоритмов считаются \"признаками\", и по этим признакам обучается линейная регрессия. В итоге веса линейной регрессии как раз будут показывать веса базовых алгоритмов.\n",
    "\n",
    "Стекинг - это более общий подход, в котором вместо линейной регрессии обучают любой другой алгоритм машинного обучения (его называют мета-алгоритмом). Вновь признаками являются предсказания базовых алгоритмов, а целевые переменные берутся из выборки.\n",
    "\n",
    "Таким образом, блендинг - это частный случай стекинга, в котором в качестве мета-алгоритма используется линейная модель. \n",
    "\n",
    "В стекинге и блендинге очень важно, чтобы базовые алгоритмы и мета-алгоритм обучались на разных выборках: базовые модель - на обучающей, мета-алгоритм - на валидационной. В этом случае мета-алгоритм будет выучивать важности базовых алгоритмов (какой вклад вносит каждый базовый алгоритм) на основе того, какие предсказания базовые алгоритмы делают на _новых_ данных.\n",
    "\n",
    "#### Задача 5.\n",
    "Предположим, что мы построили линейную регрессию и kNN на данных для задачи регрессии. Теперь мы хотим настроить веса при каждом из этих двух алгоритмов по валидационной выборке, состоящей из трех объектов. Предсказания линейной регрессии на этих трех объектах равны (-1, 7, 2), а предсказания kNN равны (-0.5, 3, 0). Правильные ответы равны (-0.8, 8, 1.5). Найдите оптимальные с точки зрения квадратичной функции потерь веса при каждом из двух алгоритмов с помощью блендинга. Вам понадобится формула оптимальных весов линейной регрессии $w=(X^T X)^{-1} X^T Y$. \n",
    "\n",
    "__Решение.__\n",
    "Блендинг работает следующим образом: мы рассматриваем предсказания базовых алгоритмов как новые признакии настраиваем линейную регрессию на правильные ответы. Составим такую выборку:\n",
    "\n",
    "| Признак 1=предск. лин. рег. | Признак 2=предск. kNN | Ответ|\n",
    "|-----------|-----------|-------|\n",
    "| -1         | -0.5        | -0.8   |\n",
    "| 7         | 3         | 8  |\n",
    "| 2         | 0         | 1.5   |\n",
    "\n",
    "Первые два стобца образуют матрицу объекты-признаки $X$, а последний стобец - вектор $Y$. Осталось посчитать веса по формуле:\n",
    "\n",
    "$$X^T X = \\begin{bmatrix}\n",
    "54 & 21.5\\\\\n",
    "21.5 & 9.25 \n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "$$\n",
    "X^T Y = \\begin{bmatrix}\n",
    "59.8 \\\\\n",
    "24.4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Теперь можно найти веса, решив квадратное уравнение с матрицей $X^T X$ и  правой частью $X^T Y$, сделать это можно с помощью np.linalg.solve. Получим вес первого алгоритма 0.88, вес второго алгоритма - 0.57.\n",
    "\n",
    "Предсказания в блендинге выполняются как и для обычной композиции: методом суммирования предсказания базовых алгоритмов с весами.\n",
    "\n",
    "Для блендинга очень важно, чтобы веса базовых алгоритмов настраивались на отдельной, валидационной выборке. Таким образом, базовые алгоритмы будут обучаться на одной части выборки, а веса будут подбираться на другой части выборки. В этом случае при подборе весов мы будем учитывать, как базовые алгоритмы работают на новых данных, а не на обучающих, а именно это нам и нужно в практических задачах. \n"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 113,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
